<!--
/*
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <title>three.ar.js - Boilerplate</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }
    #info {
      position: absolute;
      left: 50%;
      bottom: 0;
      transform: translate(-50%, 0);
      margin: 1em;
      z-index: 10;
      display: block;
      line-height: 2em;
      text-align: center;
    }
    #info * {
      color: #fff;
    }
    .title {
      background-color: rgba(40, 40, 40, 0.4);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    .links {
      background-color: rgba(40, 40, 40, 0.6);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
<!-- <div id="info">
    <span class="title">Boilerplate scene</span><br/>
    <span class="links">
      <a href="https://github.com/google-ar/three.ar.js">three.ar.js</a> -
      <a href="https://developers.google.com/ar/develop/web/getting-started#examples">examples</a>
    </span>
</div> -->
<script src="../third_party/three.js/three.js"></script>
<script src="../third_party/three.js/VRControls.js"></script>
<script src="../third_party/three.js/OBJLoader.js"></script>
<script src="../third_party/three.js/MTLLoader.js"></script>
<script src="../dist/three.ar.js"></script>
<script src="../third_party/three.js/DRACOLoader.js"></script>
<script src="../third_party/three.js/GLTFLoader.js"></script>
<script>
// declare
var vrDisplay, vrControls, arView;
var canvas, camera, scene, renderer, mixer;
var prevTime, raycaster, shooting, dragon;
var projectile = [];
var updateFunc = [];
var clock = new THREE.Clock();
var ProjectileSpeed = 1;
var projectileLimit = 100;
var projectileIndex= 0;

// declare function
rmProjectil = function (rmProjectilList)  {
  var descIndex = 0;
  for (i of rmProjectilList) {
   // var selectedObject = scene.getObjectByName(object.name);
   scene.remove(projectile[i].obj)
   projectile.splice(i-descIndex, 1);
   descIndex+=1;
  }
}
makeSphere = function() {
  var geometry = new THREE.SphereGeometry( 5, 32, 32 );
  var material = new THREE.MeshBasicMaterial( {color: 0xffff00} );
  var sphere = new THREE.Mesh( geometry, material );
  sphere.position.copy(camera.position)
  console.log(camera.quaternion)
  scene.add( sphere );
  return sphere;
}
//  makeShape is return object
makeProjectile = function(makeShape, _velocity) {
  var object = makeShape();
  var name = 'projectile'+projectileIndex;
  projectileIndex+=1;
  return {
    limit: 0,
    name: name,
    obj: object,
    // velocity: _velocity.applyQuaternion(new Three.vector3().quaternion)
    velocity: new THREE.Vector3()
  }
}


/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
var update = updateGenerator(updateFunc);
THREE.ARUtils.getARDisplay().then(function (display) {
  if (display) {
    vrDisplay = display;
    init().then(function(d) {
      console.log('its okay');
      console.log('update', update)
      update();
    });
  } else {
    THREE.ARUtils.displayUnsupportedMessage();
  }
});

var loader = new THREE.GLTFLoader();

async function init() {

  // Setup the three.js rendering environment
  renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;
  canvas = renderer.domElement;
  document.body.appendChild(canvas);
  scene = new THREE.Scene();

  // Creating the ARView, which is the object that handles
  // the rendering of the camera stream behind the three.js
  // scene
  arView = new THREE.ARView(vrDisplay, renderer);

  // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
  // except when using an AR-capable browser, the camera uses
  // the projection matrix provided from the device, so that the
  // perspective camera's depth planes and field of view matches
  // the physical camera on the device.
  camera = new THREE.ARPerspectiveCamera(
    vrDisplay,
    60,
    window.innerWidth / window.innerHeight,
    vrDisplay.depthNear,
    vrDisplay.depthFar );

  // VRControls is a utility from three.js that applies the device's
  // orientation/position to the perspective camera, keeping our
  // real world and virtual world in sync.
  vrControls = new THREE.VRControls(camera);
  raycaster = new THREE.Raycaster( new THREE.Vector3(), new THREE.Vector3( 0, - 1, 0 ), 0, 10 );

  config = {
    gltfPath: '../model/dragon/scene.gltf',
    decoderPath : '../third_party/draco/',
    GLTFLoader: THREE.GLTFLoader,
    DRACOLoader: THREE.DRACOLoader
  };
  THREE.ARUtils.newLoadModel(config).then(function(gltf) {
    dragon = gltf.scene.children[0].children[0].children[0].children[0];
    mixer = new THREE.AnimationMixer(dragon);
    var animations = gltf.animations;
    if ( animations && animations.length ) {
      var animation = animations[4];
      var action = mixer.clipAction( animation );
      action.play();
    }
    dragon.scale.set(20,20,20);
    dragon.rotateX( - Math.PI/2 );
    dragon.position.x = 0;
    dragon.position.y = -20;
    dragon.position.z = -20;
    scene.add(dragon);
  });

  // Bind our event handlers
  window.addEventListener('resize', onWindowResize, false);
  renderer.domElement.addEventListener('touchstart', function(event) {
    shooting= true;
 });
 // Stop the current draw stroke when the user finishes the touch.
 renderer.domElement.addEventListener('touchend', function(event) {
    shooting = false;
 });
  return new Promise(function(resolve, reject){ resolve("resolve")});
} // end init

/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
 function updateGenerator(args) {


	  var animate = function() {
	  // Clears color from the frame before rendering the camera (arView) or scene.
	  renderer.clearColor();

	  // Render the device's camera stream on screen first of all.
	  // It allows to get the right pose synchronized with the right frame.
	  arView.render();
    if (mixer) mixer.update(clock.getDelta());
    var time = performance.now();
    var delta = ( time - prevTime ) / 1000;
    prevTime = time;
	  // Update our camera projection matrix in the event that
	  // the near or far planes have updated

    camera.updateProjectionMatrix();

    // Update our perspective camera's positioning
    vrControls.update();
    // shoot
    if (shooting) projectile.push(makeProjectile(makeSphere, new THREE.Vector3(1,1,1)));

    var rmProjectilList = [];
    // animate Projectile
    projectile.forEach((d, index, object) => {
      // move Projectole
      d['obj'].translateX(d['velocity'].x * ProjectileSpeed * delta);
      d['obj'].translateY(d['velocity'].y * ProjectileSpeed * delta);
      d['obj'].translateZ(d['velocity'].z * ProjectileSpeed * delta);
      d['limit'] +=1;
      raycaster.ray.origin.copy(d['obj'].position);
      // var intersections = raycaster.intersectObjects(dragon.children);
      // intersections.length > 0;
      var onObject = false;
      if (onObject === true || d['limit'] == projectileLimit) {
        if (onObject) {
          console.log('충돌햇쪄');
        }
        rmProjectilList.push(index);
      }
    });
    rmProjectil(rmProjectilList);


		// custom update
		args.forEach(function(func) {func()});

	  renderer.clearDepth();
	  renderer.render(scene, camera);

	  // Kick off the requestAnimationFrame to call this function
	  // when a new VRDisplay frame is rendered
	  vrDisplay.requestAnimationFrame(animate);
	}
  return animate;
}
/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}

</script>
</body>
</html>
